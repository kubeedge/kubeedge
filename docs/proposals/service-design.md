---
title: Service Design
status: Pending
authors:
    - "@qizha"
approvers:
  - "@kevin-wangzefeng"
  - "@CindyXing"
creation-date: 2019-03-20
last-updated: 2019-03-20
---

# Service support on edge

## Abstract
To support service capabilities on edge to support microservice communication cross cloud and edge.
The service discovery, commuunication should be considered in this feature.
Developers can define services on top of the ddeployments deployed on the cloud or edges in a unified manner without caring about their location. The service name is the only thing they need to know to do the communication. For example, the following address can be used for a REST  request:
`http://{service_name}/resources`

## Motivation
The cloud native and microservice architecture becoming more and more popular and the edge node is becoming more and more powerful. The user want to separate their application to multiple microservice and some of them need to be deployed in edge node to get close to the data generated by deivces. By simply the development, the user need to use the same michanism to do the service discovery and communication with what they are doing on cloud.

## Constraints and Assumptions
1. Since the edge environment can be some non-standard system to running on some specific devices so we should not rely on the kernel network capability. In that way, we need to use userspace proxy to implement the data proxy on edge.
2. With the same reason, clusterIP is not supported on Edge.
3. With the same reason, no DNS services available for edge.
4. The identification and authentication should be handled by microservices.
5. When service communication between edge to edge, they may work offline. With the purpose to deliver a "expected result" to the user system, the service definition should be push down to the edge right after the definition operation. That is to say, the istio model may not be suitable for edge, in istio model, the service definition is pull from K8S master when the service calling happens.
6. Only support HTTP communication in the first step

## Use cases
<img src="../images/proposals/service-design.png">

### Register the service located on cloud
* CS0.1: User create service(type ClusterIP) in K8S API Server
* CS0.2: EC get the service definition and create router rules with the edge servicebus as source and service clusterIP as target.
* CS0.3: Send the service definition to edge

### Register the service located on edge
* CS1: User create service(headless service without ClusterIP) in K8S API Server
* CS2, CS3: EC get the service definiton and update the service ClusterIP to itself. Then create router rule with the EC(router) address as the source and edge servicebus as target.
* CS4: Send the service definition to edge

### Service discovery on cloud
* Application access service with the same mechanism no matter it located on cloud or edge

### Service discovery on edge
* Need to setup http_proxy in the container(can be done automatically) with the address of EdgeHub. Then the application can vist the service provider via `http://{service_name}/resource`. EdgeHub get the service name part from the request as a reverse proxy, then pick up one POD to redirect the request.

### Service communication from cloud to edge
* ESD1: Application on cloud visit service with clusterIP and request goes to EC(refer to step CS2, CS3)
* ESD2: Router find out the PODs in this service and pick one with some kind of load balance mechanism. Then send the request to the choosen edge with the router rule set in CS3.
* ESD3: EdgeHub get the request and redirect to the POD

### Service communication between edges
* ESR1: Application send the request to EdgeHub(refer to the "Service discovery on edge")
* ESR2: EdgeHub pick one POD in this service with some kind of load balance mechanism. If the target is in the same node, just forward the request. If not, edgehub wrapper the request and send to the target.
* ESR3: EdgeHub open the wrapped package and forward to the POD

### Service communication from edge to cloud
* ESU1: Application send the request to EdgeHub(refer to the "Service discovery on edge")
* ESU2: EdgeHub pick one POD in this service with some kind of load balance mechanism. The target is on cloud, EdgeHub send the request to cloud.
* ESU3: Router send the request to the corresponding POD on cloud following the rule created in CS0.2